if(family==3){
range=c(1.01, 20)
}
##  Dirichlet
if(family==4){
range=c(0.01, 20)
}
return(range)
}
LL.BiTC <- function(par, x, family){
n=nrow(x)
x_c=x[,1];x_d=x[,2]
##  log-likelihood for HR
if(family==1){
ll=sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)))
#ll=sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)/(2-2*pnorm(sqrt(par)/2))))
#ll=-(n/2)*log(par)-(1/(2*par))*sum((log(x_c/x_d)-par/2)^2) # Note that there is no the extremal coefficient
}
##  log-likelihood for Negative logistic
if(family==2){
#ll=sum(log((1+par)*(x_c*x_d)^(-par-1)*(x_c^(-par)+x_d^(-par))^(-1/par-2)))
ll=n*log(par+1)-(par+1)*sum(log(x_c*x_d))-(1/par+2)*sum(log(x_c^(-par)+x_d^(-par)))
}
##  log-likelihood for logistic
if(family==3){
ll=n*log(par-1)+(par-1)*sum(log(x_c*x_d))+(1/par-2)*sum(log(x_c^(par)+x_d^(par)))
}
##  log-likelihood for Dirichlet
if(family==4){
B=gamma(par+1)*gamma(par)/gamma(2*par+1)
ll=-n*log(B)-(2*par+1)*sum(log(x_c+x_d))+par*sum(log(x_c*x_d))
}
if (is.finite(ll)) {
return(-ll) #returns the negative log-likelihood value
}else {
return(-10^305)
}
}
LL.BiInvPa <- function(par, x, family){
n=nrow(x)
x_c=x[,1];x_d=x[,2]
##  log-likelihood for HR
if(family==1){
#ll=sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)/(2-2*pnorm(sqrt(par)/2))))
ll=graphicalExtremes:::loglik_HR(data = 1/x,Gamma = par,cens = F)[1] # switch to Pareto scale / check if they are same
}
##  log-likelihood for Negative logistic
if(family==2){
ll=n*log(par+1)-(par+1)*sum(log(x_c*x_d))-(1/par+2)*sum(log(x_c^(-par)+x_d^(-par)))-n*log(2-2^(-1/par))
}
##  log-likelihood for logistic
if(family==3){
ll=n*log(par-1)+(par-1)*sum(log(x_c*x_d))+(1/par-2)*sum(log(x_c^(par)+x_d^(par)))-n*log(2^(1/par))
}
##  log-likelihood for Dirichlet
if(family==4){
B=gamma(par+1)*gamma(par)/gamma(2*par+1)
ll=-n*log(B)-(2*par+1)*sum(log(x_c+x_d))+par*sum(log(x_c*x_d))
}
if (is.finite(ll)) {
return(ll) #returns the loglik
}else {
return(10^305)
}
}
mleBiTC <- function(ft, family, data, range){
ML.out=optimise(f = ft,family=family,x=data,maximum = F,interval = range)
ML=ML.out$minimum
return(ML)
}
mleBiCop <- function(ft, family, data, range){
ML.out=optimise(f = ft,family=family,u=data,maximum = F,interval = range)
ML=ML.out$minimum
return(ML)
}
ml1.2=mleBiTC(ft = loglik.BiExp, family=fam1[k,i], data = Z1.2, range = ParRangeExp(fam1[k,i]))
ml1.2
ml2.1=mleBiTC(ft = loglik.BiExp, family=fam1[k,i], data = Z2.1, range = ParRangeExp(fam1[k,i]))
ml2.1
# Lambda(x1|x2)
direct <- CondTC(x1 = Z1.2[,1],x2 = Z1.2[,2],par = MLest,family = fam1[k,i])
MLest=(ml1.2+ml2.1)/2 # averaged MLE
# Lambda(x1|x2)
direct <- CondTC(x1 = Z1.2[,1],x2 = Z1.2[,2],par = MLest,family = fam1[k,i])
# Lambda(x2|x1)
indirect <- CondTC(x1 = Z2.1[,1],x2 = Z2.1[,2],par = MLest,family = fam1[k,i])
loglik.BiExp
mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z1.2, range = ParRangeTC(fam1[k,i]))
ParRangeTC <- function(family){
##  Husler-Reiss
if(family==1){
range=c(0.01, 20)
}
##  Negative logistic
if(family==2){
range=c(0.01, 20)
}
##  Logistic
if(family==3){
range=c(1.01, 20)
}
##  Dirichlet
if(family==4){
range=c(0.01, 20)
}
return(range)
}
mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z1.2, range = ParRangeTC(fam1[k,i]))
diag(XVS$xmat[,,1])
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if real data are used, then need to permute columns
dior <- diag(XVS$xmat[,,1])
dior
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if real data are used, then need to permute columns
dior <- diag(XVS$xmat[,,4])
dior
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if real data are used, then need to permute columns
dior <- diag(XVS$xmat[,,5])
dior
reorder(Diag = dior)
reorder
varIndloc(Diag = dior)
varIndexloc(Diag = dior)
dior[1:length(dior)]
order.new=varIndexloc(Diag = dior)
data
order.new
data[, order.new]
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if the real data are used, then need to permute columns (relabel the variable indices)
dior <- diag(XVS$xmat[,,1])
dior
varIndexloc(Diag = dior)
#' @param Rank Logical; whether rank transformation is performed or not (\code{Rank=T}; default). It switches from Pareto scale to uniform scale.
#' @param qt Numeric; a lower threshold for the rank transformation.
#'
#' @return
#' A list of three components: the matrix of sequentially estimated parameters are stored in `Params`,
#' the estimated dependence measures are stored in the matrix `DepMeasure` where the first row has empirical Chi values and subsequent trees have empirical Kendall's Tau,
#' and the effective sample size for each edge in the vine tree is stored in the matrix `EffectSamp`
#' @export
#'
#' @examples
XVineSeqEst <- function(data, Rank=T, qt=0.2, XVS, method = "mle")
{
d <- ncol(data)
##  Noe that the 'XVineSeqEst' function uses multivariate 'inverted' Pareto samples
##  If you directly use samples from the limiting distribution, they must be ones from Pareto distribution with Pareto margin.
if(Rank){
data <- ParetoTransRank(data = data, u_quan = qt, scaleType = "U")
}
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if the real data are used, then need to permute columns (relabel the variable indices)
dior <- diag(XVS$xmat[,,1])
order.new=varIndexloc(Diag = dior)
data <- data[,order.new]
M <- standardStrMtx(XVS$xmat[,,1]) # reconstruct the structure matrix with diagonal elements in increasing order
MaxMat <- createMaxMtx(Matrix = M) # define a max-matrix
fam1 <- XVS$fmat[,,1] # store the family matrix corresponding to the structure matrix 'M'
Params <- matrix(0, d, d)
#Params2 <- matrix(0, d, d) # to be used when copula families with two parameters considered
DepMeasure <- matrix(0, d, d)
EffectSamp <- matrix(0, d, d)
logLiks <- matrix(0, d, d)
Vdir <- list() # store the pseudo data corresponding to the first argument
Vindir <- list() # store the pseudo data corresponding to the second argument
for(k in 1:(d-1)){
if(k==1){
for(i in d:2){ #k=1 / i=5,4,3,2
m <- MaxMat[1, i]
Z=data[,c(i,m)] # ex: (i,m)=(5,4)
Z1.2=Z[Z[,2]<1,] #r(x5,x4) given x4<1. To coincide with the specified percentile, the equality is included.
Z2.1=Z[Z[,1]<1,c(2,1)] #r(x4,x5) given X5<1
ml1.2=mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z1.2, range = ParRangeTC(fam1[k,i]))
ml2.1=mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z2.1, range = ParRangeTC(fam1[k,i]))
MLest=(ml1.2+ml2.1)/2 # averaged MLE
#chi <- sum(Z1.2[,1] < 1)/nrow(Z1.2)  # under the rank trans, chi1=chi2
chi1 <- sum(Z1.2[,1] < 1)/nrow(Z1.2)
chi2 <- sum(Z2.1[,1] < 1)/nrow(Z2.1)
chi <- mean(c(chi1,chi2))
# Lambda(x1|x2)
direct <- CondTC(x1 = Z1.2[,1],x2 = Z1.2[,2],par = MLest,family = fam1[k,i])
# Lambda(x2|x1)
indirect <- CondTC(x1 = Z2.1[,1],x2 = Z2.1[,2],par = MLest,family = fam1[k,i])
Vdir[[i]]=direct
Vindir[[i]]=indirect
Params[k,i]=MLest
DepMeasure[k,i]=chi
#EffectSamp[k,i]=nrow(Z[apply(Z<1,1,any),])
EffectSamp[k,i]=nrow(Z1.2)+nrow(Z2.1)-nrow(Z[apply(Z<=1,1,all),])
}
}
if(k==2){
for(i in d:3){ #k=2 / i=5,4,3
m <- MaxMat[2, i]
zr1 <- Vdir[[i]]
zr2 <- if (m == M[2, i]) {
Vdir[[m]]
}else {
Vindir[[m]]
}
Z=cbind(zr1,zr2)
# ML estimate
MLest=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle", se = FALSE)$par
# C_1|2(u1|u2)
direct <- BiCopHfunc2(zr1, zr2, family = fam1[k,i], par = MLest, par2 = 0, check.pars = FALSE)
# C_2|1(u2|u1)
indirect <- BiCopHfunc2(zr2, zr1, family = fam1[k,i], par = MLest, par2 = 0, check.pars = FALSE)
Vdir[[i]]=direct
Vindir[[i]]=indirect
Params[k,i]=MLest
DepMeasure[k,i]=cor(Z[,1],Z[,2], method = "kendall")
#DepMeasure[k,i]=VineCopula:::TauMatrix(Z)[1,2] # same as above
EffectSamp[k,i]=nrow(Z)
}
}
if(k > 2){
for(i in d:(k+1)){ #s=3 / i=5,4
Out=PseudoCop(j = k-1, cind = i, data = data, StrMtx = M, fam = fam1, MaxMtr = MaxMat, Par = Params)
##  'PseudoCop' defines the pseudo data with the conditioned support
##  j: # of conditioning variables ,cind: fix the column
m <- MaxMat[k, i]
##  For T_k, k>2, we use the pseudo data from 'Out'
zr1 <- Out$Vdir[[i]]
zr2 <- if (m == M[k, i]) {
Out$Vdir[[m]]
}else {
Out$Vindir[[m]]
}
Z=cbind(zr1,zr2)
MLest=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle",se = FALSE)$par
Params[k,i]=MLest
DepMeasure[k,i]=cor(Z[,1],Z[,2], method = "kendall")
EffectSamp[k,i]=nrow(Z)
}
}
}
return(list("Params"=Params,"DepMeasure"=DepMeasure,"EffectSamp"=EffectSamp))
}
SeqEstOut=XVineSeqEst(data = Dat_P, Rank = T, qt = 0.05, XVS=XVS, method = 'mle')
#' The available tail copula families are:
#' * 1=Husler-Reiss
#' * 2=Negative logistic
#' * 3=Logistic
#' * 4=Dirichlet
#'
#' @return A numeric vector of the bivariate tail copula with a fixed argument.
#' @export
#'
#' @references Kiriliouk, A., Lee, J., & Segers, J. (2023). X-Vine Models for Multivariate Extremes. arXiv preprint arXiv:2312.15205.
CondTC <- function(x1,x2,par,family){
##  Log-Gaussian dist (HR)
if(family==1){
CondExp1.2=stats::pnorm(q = log(x1/x2),mean = par/2,sd = sqrt(par))
}
##  Negative logistic
if(family==2){
if(par < 1e-05){
CondExp1.2=0
}else{
CondExp1.2=((x1/x2)^(-par)+1)^(-1/par - 1)
}
}
##  Logistic model
if(family==3){
if(par==1){
CondExp1.2=0
}else{
CondExp1.2=1-((x1/x2)^par+1)^(1/par-1)
}
}
##  Dirichlet model
if(family==4){
CondExp1.2=stats::pbeta(x1/(x1+x2),par+1,par)
}
return(CondExp1.2)
}
SeqEstOut=XVineSeqEst(data = Dat_P, Rank = T, qt = 0.05, XVS=XVS, method = 'mle')
PseudoCop <- function(j, cind, data, StrMtx=M, fam=fam1, MaxMtr=MaxMat, Par=Params){
d <- ncol(data)
#M <- XVS$xmat[,,1]
#M <- ReorderStrMtx(XVS$xmat[,,1])
#fam1 <- XVS$fmat[,,1]
#MaxMat <- createMaxMtx(Matrix = M)
# For example, if j=2 the number of conditioning variables in D(e), then
# k-> l=1,2 tree levels
# i-> s=5,4,3,2 / 5,4,3 / 5,4 each column
VdirC <- list()
VindirC <- list()
for(l in 1:j){
if(l==1){
for(s in d:(l+1)){
ind=StrMtx[1:j,cind] #does not depend on "l"
#CondData <- data[data[,ind[1]]<1 & data[,ind[2]]<1 ,]
CondData <- data[apply(data[,c(ind)],1,function(x)all(x<1)),]
m <- MaxMtr[l, s]
Z=CondData[,c(s,m)] # 54
Z1.2=Z[Z[,2]<1,] #lambda5.4 given X4<1
Z2.1=Z[Z[,1]<1,c(2,1)] #lambda4.5 given X5<1
direct <- CondTC(x1 = Z1.2[,1],x2 = Z1.2[,2],par = Par[l,s],family = fam[l,s])
indirect <- CondTC(x1 = Z2.1[,1],x2 = Z2.1[,2],par = Par[l,s],family = fam[l,s])
VdirC[[s]]=direct
VindirC[[s]]=indirect
}
}
if(l > 1){
for(s in d:(l+1)){
m <- MaxMtr[l, s]
zr1 <- VdirC[[s]]
zr2 <- if (m == StrMtx[l, s]) {
VdirC[[m]]
}else {
VindirC[[m]]
}
Z=cbind(zr1,zr2)
#direct <- CondCop(u1 = zr1,u2 = zr2,par = Par[l,s],family = fam[l,s])
#indirect <- CondCop(u1 = zr2,u2 = zr1,par = Par[l,s],family = fam[l,s])
direct <- BiCopHfunc2(u1 = zr1,u2 = zr2,par = Par[l,s],family = fam[l,s])
indirect <- BiCopHfunc2(u1 = zr2,u2 = zr1,par = Par[l,s],family = fam[l,s])
VdirC[[s]]=direct
VindirC[[s]]=indirect
}
}
}
return(list("Vdir"=VdirC,"Vindir"=VindirC))
}
SeqEstOut=XVineSeqEst(data = Dat_P, Rank = T, qt = 0.05, XVS=XVS, method = 'mle')
SeqEstOut
install()
.Last.error
check()
stats::optimise
usethis::use_import_from("stats","optimise")
rm(list = c("CondTC", "createMaxMtx", "InvTC", "LL.BiInvPa", "LL.BiTC",
"mleBiTC", "ParetoSim", "ParetoTransRank", "ParRangeTC", "revert",
"standardStrMtx", "varIndexloc", "XVineSim", "XVineSpec"))
check()
Z
Z1.2
n=nrow(Z1.2)
x_c=Z1.2[,1];x_d=Z1.2[,2]
##  log-likelihood for HR
sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)))
##  log-likelihood for HR
par=0.5
sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)))
-(n/2)*log(par)-(1/(2*par))*sum((log(x_c/x_d)-par/2)^2) # Note that there is no the extremal coefficient
##  log-likelihood for HR
sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)/(2-2*pnorm(sqrt(par)/2))))
check()
usethis::use_import_from("stats","pnorm")
check()
SeqEstOut=XVineSeqEst(data = Dat_P, Rank = T, qt = 0.05, XVS=XVS, method = 'mle')
SeqEstOut
?LL.BiTC
BiCopHfunc2
check()
##  log-likelihood for HR
sum(log(x_c^(-1)*(1/sqrt(2*pi*par))*exp(-(2*par)^(-1)*(log(x_c/x_d)-par/2)^2)/(2-2*pnorm(sqrt(par)/2))))
graphicalExtremes:::loglik_HR(data = 1/x,Gamma = par,cens = F)[1] # switch to Pareto scale / check if they are same
graphicalExtremes:::loglik_HR(data = 1/Z1.2,Gamma = par,cens = F)[1] # switch to Pareto scale / check if they are same
?BiCopEst
#' @param qt Numeric; a lower threshold for the rank transformation.
#'
#' @return
#' A list of four components: the matrix of sequentially estimated parameters are stored in `Params`,
#' the estimated dependence measures are stored in the matrix `DepMeasure` where the first row has empirical Chi values and subsequent trees have empirical Kendall's Tau,
#' , the effective sample size for each edge in the vine tree is stored in the matrix `EffectSamp`,
#' and the log-likelihood value for each edge in each tree is stored in the matrix `logLik`.
#' @export
#'
#' @examples
XVineSeqEst <- function(data, Rank=T, qt=0.2, XVS, method = "mle")
{
d <- ncol(data)
##  Noe that the 'XVineSeqEst' function uses multivariate 'inverted' Pareto samples
##  If you directly use samples from the limiting distribution, they must be ones from Pareto distribution with Pareto margin.
if(Rank){
data <- ParetoTransRank(data = data, u_quan = qt, scaleType = "U")
}
# If data are generated from XVineSim, variables are always put in increasing order 1:d
# But, if the real data are used, then need to permute columns (relabel the variable indices)
dior <- diag(XVS$xmat[,,1])
order.new=varIndexloc(Diag = dior)
data <- data[,order.new]
M <- standardStrMtx(XVS$xmat[,,1]) # reconstruct the structure matrix with diagonal elements in increasing order
MaxMat <- createMaxMtx(Matrix = M) # define a max-matrix
fam1 <- XVS$fmat[,,1] # store the family matrix corresponding to the structure matrix 'M'
Params <- matrix(0, d, d)
#Params2 <- matrix(0, d, d) # to be used when copula families with two parameters considered
DepMeasure <- matrix(0, d, d)
EffectSamp <- matrix(0, d, d)
logLiks <- matrix(0, d, d)
Vdir <- list() # store the pseudo data corresponding to the first argument
Vindir <- list() # store the pseudo data corresponding to the second argument
for(k in 1:(d-1)){
if(k==1){
for(i in d:2){ #k=1 / i=5,4,3,2
m <- MaxMat[1, i]
Z=data[,c(i,m)] # ex: (i,m)=(5,4)
Z1.2=Z[Z[,2]<1,] #r(x5,x4) given x4<1. To coincide with the specified percentile, the equality is included.
Z2.1=Z[Z[,1]<1,c(2,1)] #r(x4,x5) given X5<1
ml1.2=mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z1.2, range = ParRangeTC(fam1[k,i]))
ml2.1=mleBiTC(ft = LL.BiTC, family=fam1[k,i], data = Z2.1, range = ParRangeTC(fam1[k,i]))
MLest=(ml1.2+ml2.1)/2 # averaged MLE
#chi <- sum(Z1.2[,1] < 1)/nrow(Z1.2)  # under the rank trans, chi1=chi2
chi1 <- sum(Z1.2[,1] < 1)/nrow(Z1.2)
chi2 <- sum(Z2.1[,1] < 1)/nrow(Z2.1)
chi <- mean(c(chi1,chi2))
# Lambda(x1|x2)
direct <- CondTC(x1 = Z1.2[,1],x2 = Z1.2[,2],par = MLest,family = fam1[k,i])
# Lambda(x2|x1)
indirect <- CondTC(x1 = Z2.1[,1],x2 = Z2.1[,2],par = MLest,family = fam1[k,i])
Vdir[[i]]=direct
Vindir[[i]]=indirect
Params[k,i]=MLest
DepMeasure[k,i]=chi
#EffectSamp[k,i]=nrow(Z[apply(Z<1,1,any),])
EffectSamp[k,i]=nrow(Z1.2)+nrow(Z2.1)-nrow(Z[apply(Z<=1,1,all),])
logLiks[k,i]=LL.BiTC(par = MLest,x = Z1.2,family = fam1[k,i])
}
}
if(k==2){
for(i in d:3){ #k=2 / i=5,4,3
m <- MaxMat[2, i]
zr1 <- Vdir[[i]]
zr2 <- if (m == M[2, i]) {
Vdir[[m]]
}else {
Vindir[[m]]
}
Z=cbind(zr1,zr2)
# ML estimate
MLest=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle", se = FALSE)$par
# C_1|2(u1|u2)
direct <- BiCopHfunc2(zr1, zr2, family = fam1[k,i], par = MLest, par2 = 0, check.pars = FALSE)
# C_2|1(u2|u1)
indirect <- BiCopHfunc2(zr2, zr1, family = fam1[k,i], par = MLest, par2 = 0, check.pars = FALSE)
Vdir[[i]]=direct
Vindir[[i]]=indirect
Params[k,i]=MLest
DepMeasure[k,i]=cor(Z[,1],Z[,2], method = "kendall")
#DepMeasure[k,i]=VineCopula:::TauMatrix(Z)[1,2] # same as above
EffectSamp[k,i]=nrow(Z)
logLiks[k,i]=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle", se = FALSE)$logLik
}
}
if(k > 2){
for(i in d:(k+1)){ #s=3 / i=5,4
Out=PseudoCop(j = k-1, cind = i, data = data, StrMtx = M, fam = fam1, MaxMtr = MaxMat, Par = Params)
##  'PseudoCop' defines the pseudo data with the conditioned support
##  j: # of conditioning variables ,cind: fix the column
m <- MaxMat[k, i]
##  For T_k, k>2, we use the pseudo data from 'Out'
zr1 <- Out$Vdir[[i]]
zr2 <- if (m == M[k, i]) {
Out$Vdir[[m]]
}else {
Out$Vindir[[m]]
}
Z=cbind(zr1,zr2)
MLest=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle",se = FALSE)$par
Params[k,i]=MLest
DepMeasure[k,i]=cor(Z[,1],Z[,2], method = "kendall")
EffectSamp[k,i]=nrow(Z)
logLiks[k,i]=BiCopEst(u1 = zr1,u2 = zr2,family = fam1[k,i],method = "mle", se = FALSE)$logLik
}
}
}
return(list("Params"=Params,"DepMeasure"=DepMeasure,"EffectSamp"=EffectSamp,"logLiks"=logLiks))
}
SeqEstOut=XVineSeqEst(data = Dat_P, Rank = T, qt = 0.05, XVS=XVS, method = 'mle')
SeqEstOut$logLiks
check()
rm(list = c("PseudoCop"))
check()
#Go to github page to generate token
usethis::create_github_token()
#paste your PAT into pop-up that follows...
credentials::set_github_pat()
rmarkdown::render(README.Rmd)
?rmarkdown::render
rmarkdown::render("README.Rmd")
rmarkdown::render("README.Rmd")
rmarkdown::render("README.Rmd")
usethis::use_vignette()
usethis::use_vignette("XvineWorkflow.Rmd")
usethis::use_vignette("XvineWorkflow")
usethis::use_github_action("pkgdown")
usethis::use_pkgdown_github_pages()
rlang::last_trace()
rlang::last_trace(drop = FALSE)
usethis::use_github(private=FALSE)
usethis::use_github(private=FALSE)
#usethis::use_github(private=FALSE)
usethis::use_git_remote("origin", url = NULL, overwrite = TRUE)
usethis::use_pkgdown_github_pages()
usethis::use_pkgdown()
pkgdown::build_site()
pkgdown::build_site()
#usethis::use_github(private=FALSE)
?usethis::use_github_links
usethis::use_github_links()
use_github()
git_remotes()
usethis::use_github_links()
use_git_remote(name="JeongjinLee88",url="https://github.com/JeongjinLee88/Xvine.git",overwrite = TRUE)
git_remotes()
usethis::use_pkgdown_github_pages()
git_sitrep()
